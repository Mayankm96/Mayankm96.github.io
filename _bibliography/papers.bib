---
---

@inproceedings{1906.01304,
Author = {Mayank Mittal and Rohit Mohan and Wolfram Burgard and Abhinav Valada},
Title = {Vision-Based Autonomous UAV Navigation and Landing for Urban Search and Rescue},
Year = {2019},
abstract = {Unmanned Aerial Vehicles (UAVs) equipped with bioradars are a life-saving technology that can enable identification of survivors under collapsed buildings in the aftermath of natural disasters such as earthquakes or gas explosions. However, these UAVs have to be able to autonomously navigate in disaster struck environments and land on debris piles in order to accurately locate the survivors. This problem is extremely challenging as pre-existing maps cannot be leveraged for navigation due to structural changes that may have occurred and existing landing site detection algorithms are not suitable to identify safe landing regions on debris piles. In this work, we present a computationally efficient system for autonomous UAV navigation and landing that does not require any prior knowledge about the environment. We propose a novel landing site detection algorithm that computes costmaps based on several hazard factors including terrain flatness, steepness, depth accuracy, and energy consumption information. We also introduce a first-of-a-kind synthetic dataset of over 1.2 million images of collapsed buildings with groundtruth depth, surface normals, semantics and camera pose information. We demonstrate the efficacy of our system using experiments from a city scale hyperrealistic simulation environment and in real-world scenarios with collapsed buildings.},
booktitle = {ISRR},
journal = {Proceedings of the International Symposium of Robotics Research (ISRR)},
arxiv = {1906.01304},
html = {http://autoland.cs.uni-freiburg.de}
}

@workshop{1809.05700,
Author = {Mayank Mittal and Abhinav Valada and Wolfram Burgard},
Title = {Vision-based Autonomous Landing in Catastrophe-Struck Environments},
Year = {2018},
abstract = {Unmanned Aerial Vehicles (UAVs) equipped with bioradars are a life-saving technology that can enable identification of survivors under collapsed buildings in the aftermath of natural disasters such as earthquakes or gas explosions. However, these UAVs have to be able to autonomously land on debris piles in order to accurately locate the survivors. This problem is extremely challenging as the structure of these debris piles is often unknown and no prior knowledge can be leveraged. In this work, we propose a computationally efficient system that is able to reliably identify safe landing sites and autonomously perform the landing maneuver. Specifically, our algorithm computes costmaps based on several hazard factors including terrain flatness, steepness, depth accuracy and energy consumption information. We first estimate dense candidate landing sites from the resulting costmap and then employ clustering to group neighboring sites into a safe landing region. Finally, a minimum-jerk trajectory is computed for landing considering the surrounding obstacles and the UAV dynamics. We demonstrate the efficacy of our system using experiments from a city scale hyperrealistic simulation environment and in real-world scenarios with collapsed buildings.},
booktitle = {Workshop on Vision-based Drones: What's Next?},
maintitle = {IROS},
arxiv = {1809.05700},
video = {https://www.youtube.com/watch?v=6FEgU0kYqlM},
pdf = {papers/mittal18irosws.pdf}
}
