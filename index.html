<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Vivek Gopalakrishnan</title>
  <meta name="description" content="A simple website for a Robotics Enthusiast.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Miscellarnous -->
        <a class="page-link" href="/#publications">publications</a>
        <a class="page-link" href="/projects">projects</a>
        <a class="page-link" href="/tutorials">tutorials</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a> -->

        <!-- CV link -->
        <a class="page-link" href="/assets/documents/Mayank_CV.pdf">vitae</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title"><strong>Mayank</strong> Mittal</h1>
    <h5 class="post-description">Graduate Student | Robotics, Systems, and Control, ETH Zurich</h5>
  </header>

  <article class="post-content <strong>Mayank</strong> Mittal clearfix">
    
  <div class="profile col one right">
    
      <img class="one" src="/assets/img/prof_pic.jpg">
    
    
  </div>


<p>I am a graduate student in the Robotics, Systems, and Controls program at ETH Zurich.
As a part of the <a href="https://rsl.ethz.ch/">Robotic Systems Lab</a>, headed by
<a href="http://www.rsl.ethz.ch/the-lab/people/person-detail.html?persid=121911">Marco Hutter</a>,
I work on learning robot control for mobile manipulators.</p>

<p>Over the past few years, I have been fortunate to work on a variety of robotic systems. Most of my time
during my undergrad was spent developing autonomous underwater vehicles and co-founding the institute’s <a href="https://auviitk.com">AUV team</a>.
During the summer of 2017, I worked with <a href="http://www2.informatik.uni-freiburg.de/~valada/">Abhinav Valada</a> and <a href="http://www2.informatik.uni-freiburg.de/~burgard/">Wolfram Burgard</a> at the University of Freiburg, Germany on building autonomous aerial systems for urban search and rescue. Most recently, my internship at <a href="https://nnaisense.com/">NNAISENSE</a> involved safe-grasping of objects using manipulators.</p>

<p>If you have any questions or would like to collaborate, feel free to reach out through
<a href="mailto:mittalma@ethz.ch">email</a>!</p>

<div class="post">

  
    <div class="news">
  <h2>news</h2>
  
    <table>
    
    
      <tr>
        <td class="date">May 18, 2020</td>
        <td class="announcement">
          
            Excited to start my master thesis with <a href="http://animesh.garg.tech/">Animesh Garg</a> at
<a href="https://pairlab.github.io/">PAIR Lab</a>, University of Toronto!

          
        </td>
      </tr>
    
      <tr>
        <td class="date">Jan 22, 2020</td>
        <td class="announcement">
          
            Our paper on <em>‘Learning Camera Miscalibration Detection’</em> from my work at <a href="https://asl.ethz.ch/">Autonomous Systems Lab, ETH Zurich</a> is accepted to <a href="https://www.icra2020.org/">ICRA 2020</a>

          
        </td>
      </tr>
    
      <tr>
        <td class="date">Sep 1, 2019</td>
        <td class="announcement">
          
            Started my internship with the Intelligent Automation team at <a href="https://nnaisense.com/">NNAISENSE</a>, Lugano!

          
        </td>
      </tr>
    
      <tr>
        <td class="date">Aug 2, 2019</td>
        <td class="announcement">
          
            Our paper on <em>‘Vision-Based Autonomous UAV Navigation and Landing for Urban Search and Rescue’</em> from my internship at <a href="http://ais.informatik.uni-freiburg.de/index_en.php">Autonomous Intelligent Systems, University of Freiburg</a> is accepted to <a href="http://h2t-projects.webarchiv.kit.edu/Projects/ISRR2019/">ISRR 2019</a>

          
        </td>
      </tr>
    
      <tr>
        <td class="date">Jul 27, 2019</td>
        <td class="announcement">
          
            I will be interning with the Intelligence Control team at <a href="https://nnaisense.com/">NNAISENSE</a> in Lugano, Switzerland from Septmember onwards!

          
        </td>
      </tr>
    
    </table>
  
</div>

  

</div>

<hr />

<h2 id="publications"><strong>publications</strong></h2>

<ol class="bibliography"><li><div id="2002.10451" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="/assets/img/teasers/lyap_mpc.png" />
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Neural Lyapunov Model Predictive Control</span>
      <span class="author">
        
          
            
              
                <em><b>Mayank Mittal</b></em>,
              
            
          
        
          
            
              
                
                  <a href="https://ch.linkedin.com/in/marco-gallieri-166a0421" target="_blank">Marco Gallieri</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://ch.linkedin.com/in/aqua83" target="_blank">Alessio Quaglino</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://ch.linkedin.com/in/seyed-sina-mirrazavi-salehian-11772856" target="_blank">Seyed Sina Mirrazavi Salehian</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www.idsia.ch/~koutnik" target="_blank">Jan Koutnik</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em> (Under Review) </em>
      
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2002.10451" target="_blank">arXiv</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This paper presents <i>Neural Lyapunov MPC</i>, an algorithm to alternately train a Lyapunov neural network and a stabilising constrained Model Predictive Controller (MPC), given a neural network model of the system dynamics. This extends recent works on Lyapunov networks to be able to train solely from expert demonstrations of one-step transitions. The learned Lyapunov network is used as the value function for the MPC in order to guarantee stability and extend the stable region. Formal results are presented on the existence of a set of MPC parameters, such as discount factors, that guarantees stability with a horizon as short as one. Robustness margins are also discussed and existing performance bounds on value function MPC are extended to the case of imperfect models. The approach is tested on unstable non-linear continuous control tasks with hard constraints. Results demonstrate that, when a neural network trained on short sequences is used for predictions, a one-step horizon Neural Lyapunov MPC can successfully reproduce the expert behaviour and significantly outperform longer horizon MPCs.</p>
    </span>
    
  </div>
</div>
</li>
<li><div id="2001.01234" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="/assets/img/teasers/miscalib.png" />
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Learning Camera Miscalibration Detection</span>
      <span class="author">
        
          
            
              
                
                  <a href="https://asl.ethz.ch/the-lab/people/person-detail.MjMxMjQw.TGlzdC8xNTg0LDEyMDExMzk5Mjg=.html" target="_blank">Andrei Cramariuc</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.linkedin.com/in/aleksandar-petrov/" target="_blank">Aleksandar Petrov</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.linkedin.com/in/rohit-suri-0966b0b3/" target="_blank">Rohit Suri</a>,
                
              
            
          
        
          
            
              
                <em><b>Mayank Mittal</b></em>,
              
            
          
        
          
            
              
                
                  <a href="https://mavt.ethz.ch/the-department/people/person-detail.Mjk5ODE=.TGlzdC81NTMsLTY5MzYxOTMw.html" target="_blank">Roland Siegwart</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://n.ethz.ch/~cesarc/" target="_blank">Cesar Cadena</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>ICRA</em>
      
      
        
          2020
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2005.11711" target="_blank">arXiv</a>]
    
    
    
    
    
    
    
    
      [<a href="http://github.com/ethz-asl/camera_miscalib_detection" target="_blank">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Self-diagnosis and self-repair are some of the key challenges in deploying robotic platforms for long-term real-world applications. One of the issues that can occur to a robot is miscalibration of its sensors due to aging, environmental transients or external disturbances. Precise calibration lies at the core of a variety of applications, due to the need to accurately perceive the world. However, while a lot of work has focused on calibrating the sensors, not much has been done towards identifying when a sensor needs to be recalibrated. In this paper, we focus on a data-driven approach to learn the detection of miscalibration in vision sensors, specifically RGB cameras. Our contributions include a proposed miscalibration metric for RGB cameras and a novel semi-synthetic dataset generation pipeline based on this metric. Additionally, by training a deep convolutional neural network, we demonstrate the effectiveness of our pipeline to identify whether a recalibration of the camera’s intrinsic parameters is required or not.</p>
    </span>
    
  </div>
</div>
</li></ol>

<ol class="bibliography"><li><div id="1906.01304" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="/assets/img/teasers/vision_uav.png" />
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Vision-based Autonomous UAV Navigation and Landing for Urban Search and Rescue</span>
      <span class="author">
        
          
            
              
                <em><b>Mayank Mittal</b></em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.linkedin.com/in/rohit-mohan-508112142/" target="_blank">Rohit Mohan</a>,
                
              
            
          
        
          
            
              
                
                  <a href="http://www2.informatik.uni-freiburg.de/~burgard/" target="_blank">Wolfram Burgard</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www2.informatik.uni-freiburg.de/~valada/" target="_blank">Abhinav Valada</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>ISRR</em>
      
      
        
          2019
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/1906.01304" target="_blank">arXiv</a>]
    
    
    
      [<a href="http://autoland.cs.uni-freiburg.de" target="_blank">Website</a>]
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Unmanned Aerial Vehicles (UAVs) equipped with bioradars are a life-saving technology that can enable identification of survivors under collapsed buildings in the aftermath of natural disasters such as earthquakes or gas explosions. However, these UAVs have to be able to autonomously navigate in disaster struck environments and land on debris piles in order to accurately locate the survivors. This problem is extremely challenging as pre-existing maps cannot be leveraged for navigation due to structural changes that may have occurred and existing landing site detection algorithms are not suitable to identify safe landing regions on debris piles. In this work, we present a computationally efficient system for autonomous UAV navigation and landing that does not require any prior knowledge about the environment. We propose a novel landing site detection algorithm that computes costmaps based on several hazard factors including terrain flatness, steepness, depth accuracy, and energy consumption information. We also introduce a first-of-a-kind synthetic dataset of over 1.2 million images of collapsed buildings with groundtruth depth, surface normals, semantics and camera pose information. We demonstrate the efficacy of our system using experiments from a city scale hyperrealistic simulation environment and in real-world scenarios with collapsed buildings.</p>
    </span>
    
  </div>
</div>
</li></ol>

<ol class="bibliography"><li><div id="1809.05700" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="/assets/img/teasers/landing.png" />
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Vision-based Autonomous Landing in Catastrophe-Struck Environments</span>
      <span class="author">
        
          
            
              
                <em><b>Mayank Mittal</b></em>,
              
            
          
        
          
            
              
                
                  <a href="http://www2.informatik.uni-freiburg.de/~valada/" target="_blank">Abhinav Valada</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www2.informatik.uni-freiburg.de/~burgard/" target="_blank">Wolfram Burgard</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Workshop on Vision-based Drones: What’s Next?</em>
        <br />
        <em>IROS</em>
      
      
        
          2018
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/1809.05700" target="_blank">arXiv</a>]
    
    
      [<a href="https://www.youtube.com/watch?v=6FEgU0kYqlM" target="_blank">Video</a>]
    
    
    
      [<a href="/assets/documents/papers/mittal18irosws.pdf" target="_blank">PDF</a>]
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Unmanned Aerial Vehicles (UAVs) equipped with bioradars are a life-saving technology that can enable identification of survivors under collapsed buildings in the aftermath of natural disasters such as earthquakes or gas explosions. However, these UAVs have to be able to autonomously land on debris piles in order to accurately locate the survivors. This problem is extremely challenging as the structure of these debris piles is often unknown and no prior knowledge can be leveraged. In this work, we propose a computationally efficient system that is able to reliably identify safe landing sites and autonomously perform the landing maneuver. Specifically, our algorithm computes costmaps based on several hazard factors including terrain flatness, steepness, depth accuracy and energy consumption information. We first estimate dense candidate landing sites from the resulting costmap and then employ clustering to group neighboring sites into a safe landing region. Finally, a minimum-jerk trajectory is computed for landing considering the surrounding obstacles and the UAV dynamics. We demonstrate the efficacy of our system using experiments from a city scale hyperrealistic simulation environment and in real-world scenarios with collapsed buildings.</p>
    </span>
    
  </div>
</div>
</li></ol>



  </article>

  
    <div class="social">
  <span class="contacticon center">
    <a href="mailto:vgopala4@jhu.edu"><i class="fa fa-envelope-square"></i></a>
    <a href="https://scholar.google.com/citations?authorid=iVXG-IkAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar-square"></i></a>
    <a href="https://github.com/Mayankm96" target="_blank" title="GitHub"><i class="fa fa-github-square"></i></a>
    <a href="https://www.linkedin.com/in/mayankm-0096" target="_blank" title="LinkedIn"><i class="fa fa-linkedin-square"></i></a>
    <!-- <a href="https://twitter.com/" target="_blank" title="Twitter"><i class="fa fa-twitter-square"></i></a> -->
  </span>

  <div class="col three caption">
    
  </div>
</div>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    <center>
      &copy; Copyright 2021 Vivek Gopalakrishnan.
      Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

      
    </center>
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/font-awesome.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92958928-1', 'auto');
  ga('send', 'pageview');
</script>


  </body>

</html>
